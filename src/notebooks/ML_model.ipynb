{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Changes the current path to find the source files\n",
    "current_dir = os.getcwd()\n",
    "while current_dir != os.path.abspath(\"../src\"):\n",
    "    os.chdir(\"..\")\n",
    "    current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(\"Efficient-Computing/Detection/Gold-YOLO\"))\n",
    "\n",
    "OUTPUT_DIR = \"../data/model_output\"\n",
    "\n",
    "folder_paths = [OUTPUT_DIR]\n",
    "\n",
    "# Create the output directories if they doesn't exist\n",
    "for folder_path in folder_paths:\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from plot import get_bounding_boxes, create_bboxes_image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from layers import AMF_GD_YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the AMF GD YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: \"Tree\", 1: \"Tree_disappeared\", 2: \"Tree_replaced\", 3: \"Tree_new\"}\n",
    "\n",
    "model = AMF_GD_YOLOv8(3, 1, scale=\"s\", class_names=class_names)\n",
    "\n",
    "rgb_image_path = \"../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_1.tif\"\n",
    "chm_image_path = (\n",
    "    \"../data/CHM_cropped_0p24/122000_484000/122000_484000_0_1_filtered_chm.tif\"\n",
    ")\n",
    "\n",
    "output_name = \"Model_output_test.jpg\"\n",
    "output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "\n",
    "output = model(rgb_image_path, chm_image_path, image_save_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use data augmentation with Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.703\n",
      "Time elapsed: 0.887\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=640, height=640, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.RandomBrightnessContrast(p=1.0),\n",
    "        A.GridDistortion(\n",
    "            num_steps=10,\n",
    "            distort_limit=0.1,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            normalized=False,\n",
    "            p=0.25,\n",
    "        ),\n",
    "        A.Perspective(p=0.25, interpolation=cv2.INTER_LINEAR),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"coco\", min_area=0, min_visibility=0.2, label_fields=[\"class_labels\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# image_path = \"../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_3.tif\"\n",
    "# annotations_path = \"../data/annotations_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_3.json\"\n",
    "image_path = \"../data/images_full/2023_122000_484000_RGB_hrl.tif\"\n",
    "annotations_path = \"../data/annotations_full/3_all_annotations.json\"\n",
    "\n",
    "t = time()\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "bboxes, labels = get_bounding_boxes(annotations_path)\n",
    "\n",
    "print(f\"Time elapsed: {round(time() - t, 3)}\")\n",
    "\n",
    "number_tests = 10\n",
    "\n",
    "colors = {\n",
    "    \"Tree\": (104, 201, 45),\n",
    "    \"Tree_unsure\": (255, 215, 158),\n",
    "    \"Tree_disappeared\": (158, 174, 255),\n",
    "    \"Tree_replaced\": (255, 90, 82),\n",
    "    \"Tree_new\": (251, 106, 225),\n",
    "}\n",
    "\n",
    "t = time()\n",
    "\n",
    "for i in range(number_tests):\n",
    "    transformed = transform(image=image, bboxes=bboxes, class_labels=labels)\n",
    "    transformed_image = transformed[\"image\"]\n",
    "    transformed_bboxes = transformed[\"bboxes\"]\n",
    "    transformed_class_labels = transformed[\"class_labels\"]\n",
    "\n",
    "    output_name = f\"Augmentation_test_{i}.tif\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "    cv2.imwrite(output_path, transformed_image)\n",
    "\n",
    "    bboxes_image = create_bboxes_image(\n",
    "        transformed_image,\n",
    "        transformed_bboxes,\n",
    "        labels=transformed_class_labels,\n",
    "        colors_dict=colors,\n",
    "        scores=np.random.rand((len(bboxes))),\n",
    "    )\n",
    "\n",
    "    output_name = f\"Augmentation_test_{i}_bboxes.tif\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "    cv2.imwrite(output_path, bboxes_image)\n",
    "\n",
    "print(f\"Time elapsed: {round(time() - t, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-segment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
