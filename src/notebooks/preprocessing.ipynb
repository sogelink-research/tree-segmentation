{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from osgeo import gdal\n",
    "import pdal\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from pprint import pprint\n",
    "import laspy\n",
    "import time\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "FULL_BBOXES_FOLDER = \"../../data/annotations_full/\"\n",
    "CROPPED_BBOXES_FOLDER = \"../../data/annotations_cropped/\"\n",
    "FULL_IMAGES_FOLDER = \"../../data/images_full/\"\n",
    "CROPPED_IMAGES_FOLDER = \"../../data/images_cropped/\"\n",
    "GEOTILES_LIDAR_FOLDER = \"../../data/point_clouds_geotiles/\"\n",
    "GEOTILES_NO_OVERLAP_LIDAR_FOLDER = \"../../data/point_clouds_geotiles_no_overlap/\"\n",
    "FULL_LIDAR_FOLDER = \"../../data/point_clouds_full/\"\n",
    "CROPPED_LIDAR_FOLDER = \"../../data/point_clouds_cropped/\"\n",
    "\n",
    "folder_paths = [\n",
    "    FULL_BBOXES_FOLDER,\n",
    "    CROPPED_BBOXES_FOLDER,\n",
    "    FULL_IMAGES_FOLDER,\n",
    "    CROPPED_IMAGES_FOLDER,\n",
    "    GEOTILES_LIDAR_FOLDER,\n",
    "    GEOTILES_NO_OVERLAP_LIDAR_FOLDER,\n",
    "    FULL_LIDAR_FOLDER,\n",
    "    CROPPED_LIDAR_FOLDER,\n",
    "]\n",
    "\n",
    "# # Create the output directories if they doesn't exist\n",
    "# for folder_path in folder_paths:\n",
    "#     if not os.path.exists(folder_path):\n",
    "#         os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tile size and OVERLAP\n",
    "# TILE_SIZE = 1920  # Size of each tile\n",
    "# OVERLAP = 480  # Overlap between tiles\n",
    "TILE_SIZE = 640  # Size of each tile\n",
    "OVERLAP = 0  # Overlap between tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_execution_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        print(f\"Execution of {func.__name__}({args})...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Done in {round(execution_time, 3)} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To crop LiDAR point clouds into the size of the RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_execution_time\n",
    "def merge_crop_las(\n",
    "    input_las_list: list[str], output_las: str, x_limits: tuple, y_limits: tuple\n",
    "):\n",
    "    if x_limits[0] > x_limits[1]:\n",
    "        raise Exception(\"You should have x_limits[0] <= x_limits[1]\")\n",
    "    if y_limits[0] > y_limits[1]:\n",
    "        raise Exception(\"You should have y_limits[0] <= y_limits[1]\")\n",
    "    bounds = f\"([{x_limits[0]},{x_limits[1]}],[{y_limits[0]},{y_limits[1]}])\"\n",
    "    pipeline_list = []\n",
    "    for index, input_las in enumerate(input_las_list):\n",
    "        pipeline_list.append(\n",
    "            {\"type\": \"readers.las\", \"file_name\": input_las, \"tag\": f\"A{index}\"}\n",
    "        )\n",
    "    pipeline_list.extend(\n",
    "        [\n",
    "            {\n",
    "                \"type\": \"filters.merge\",\n",
    "                \"inputs\": [f\"A{index}\" for index in range(len(input_las_list))],\n",
    "            },\n",
    "            {\"type\": \"filters.crop\", \"bounds\": bounds},\n",
    "            {\"type\": \"writers.las\", \"file_name\": output_las},\n",
    "        ]\n",
    "    )\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "    pipeline.execute()\n",
    "\n",
    "\n",
    "@measure_execution_time\n",
    "def crop_las(input_las: str, output_las: str, x_limits: tuple, y_limits: tuple):\n",
    "    if x_limits[0] > x_limits[1]:\n",
    "        raise Exception(\"You should have x_limits[0] <= x_limits[1]\")\n",
    "    if y_limits[0] > y_limits[1]:\n",
    "        raise Exception(\"You should have y_limits[0] <= y_limits[1]\")\n",
    "    bounds = f\"([{x_limits[0]},{x_limits[1]}],[{y_limits[0]},{y_limits[1]}])\"\n",
    "    pipeline_list = [\n",
    "        {\n",
    "            \"type\": \"readers.las\",\n",
    "            \"file_name\": input_las,\n",
    "        },\n",
    "        {\"type\": \"filters.crop\", \"bounds\": bounds},\n",
    "        {\"type\": \"writers.las\", \"file_name\": output_las},\n",
    "    ]\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "    pipeline.execute()\n",
    "\n",
    "\n",
    "def remove_las_overlap_from_geotiles(input_las: str, output_las: str):\n",
    "    overlap = 20\n",
    "    with laspy.open(input_las, mode=\"r\") as las_file:\n",
    "        # Get the bounding box information from the header\n",
    "        min_x = las_file.header.min[0] + overlap\n",
    "        max_x = las_file.header.max[0] - overlap\n",
    "        min_y = las_file.header.min[1] + overlap\n",
    "        max_y = las_file.header.max[1] - overlap\n",
    "\n",
    "    crop_las(input_las, output_las, (min_x, max_x), (min_y, max_y))\n",
    "\n",
    "\n",
    "def remove_las_overlap_from_geotiles_all():\n",
    "    point_clouds_overlap_folder = \"../../data/point_clouds_geotiles\"\n",
    "    point_clouds_no_overlap_folder = \"../../data/point_clouds_geotiles_no_overlap\"\n",
    "    if not os.path.exists(point_clouds_no_overlap_folder):\n",
    "        os.makedirs(point_clouds_no_overlap_folder)\n",
    "    for file_name in os.listdir(point_clouds_overlap_folder):\n",
    "        # Check if the file is a regular file (not a directory)\n",
    "        overlap_file_path = os.path.join(point_clouds_overlap_folder, file_name)\n",
    "        no_overlap_file_path = os.path.join(point_clouds_no_overlap_folder, file_name)\n",
    "        if (os.path.isfile(overlap_file_path)) and (\n",
    "            not os.path.exists(no_overlap_file_path)\n",
    "        ):\n",
    "            remove_las_overlap_from_geotiles(overlap_file_path, no_overlap_file_path)\n",
    "\n",
    "\n",
    "@measure_execution_time\n",
    "def filter_classification_las(input_las: str, output_las: str):\n",
    "    pipeline_list = [\n",
    "        {\n",
    "            \"type\": \"readers.las\",\n",
    "            \"file_name\": input_las,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.range\",\n",
    "            \"limits\": \"Classification[1:5]\",  # Keep only unclassified, ground and vegetation\n",
    "        },\n",
    "        {\"type\": \"writers.las\", \"file_name\": output_las},\n",
    "    ]\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "    pipeline.execute()\n",
    "\n",
    "\n",
    "# # Open the GeoTIFF file\n",
    "# tiff_image_test = \"../../data/images_full/2023_122000_484000_RGB_hrl.tif\"\n",
    "# ds = gdal.Open(tiff_image_test)\n",
    "# # Get the geotransform parameters\n",
    "# gt = ds.GetGeoTransform()\n",
    "# # Calculate the image coordinates\n",
    "# width = ds.RasterXSize\n",
    "# height = ds.RasterYSize\n",
    "# # Calculate the coordinates of the four corners\n",
    "# x1 = int(gt[0])\n",
    "# y1 = int(gt[3])\n",
    "# x2 = int(gt[0] + (gt[1] * width))\n",
    "# y2 = int(gt[3] + (gt[5] * height))\n",
    "# # Close the dataset\n",
    "# ds = None\n",
    "# # Crop the point cloud\n",
    "# geotiles_point_clouds_path = [\"../../data/point_clouds_geotiles/25GN1_13.LAZ\", \"../../data/point_clouds_geotiles/25GN1_18.LAZ\"]\n",
    "# geotiles_no_overlap_point_clouds_path = [\"../../data/point_clouds_geotiles_no_overlap/25GN1_13.LAZ\", \"../../data/point_clouds_geotiles_no_overlap/25GN1_18.LAZ\"]\n",
    "# for overlap_path, no_overlap_path in zip(geotiles_point_clouds_path, geotiles_no_overlap_point_clouds_path):\n",
    "#     remove_las_overlap_from_geotiles(overlap_path, no_overlap_path)\n",
    "# full_point_cloud_path = f\"../../data/point_clouds_full/{int(x1)}_{int(y1)}.laz\"\n",
    "# crop_las(geotiles_no_overlap_point_clouds_path, full_point_cloud_path, (x1, x2), (y2, y1))\n",
    "# full_point_filtered_cloud_path = f\"../../data/point_clouds_full/{int(x1)}_{int(y1)}_filtered.laz\"\n",
    "# filter_classification_las(full_point_cloud_path, full_point_filtered_cloud_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/annotations_full/3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m bboxes_path \u001b[38;5;241m=\u001b[39m FULL_BBOXES_FOLDER \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbboxes_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Load the annotation data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     bboxes_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Get the path to the full image\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tree-segment/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/annotations_full/3'"
     ]
    }
   ],
   "source": [
    "bboxes_path = FULL_BBOXES_FOLDER + \"3\"\n",
    "\n",
    "with open(bboxes_path, \"r\") as file:\n",
    "    # Load the annotation data\n",
    "    bboxes_json = json.load(file)\n",
    "\n",
    "    # Get the path to the full image\n",
    "    full_image_path = bboxes_json[\"task\"][\"data\"][\"image\"].replace(\n",
    "        \"/data/local-files/?d=\", \"/\"\n",
    "    )\n",
    "    full_image_path_tif = full_image_path.replace(\".png\", \".tif\")\n",
    "    full_image_path_tif = \"../../data/images_full/2023_122000_484000_RGB_hrl.tif\"\n",
    "\n",
    "    # Create the paths\n",
    "    output_image_prefix = os.path.splitext(os.path.basename(full_image_path_tif))[0]\n",
    "    annotation_output_directory = os.path.join(\n",
    "        CROPPED_BBOXES_FOLDER, output_image_prefix\n",
    "    )\n",
    "    if not os.path.exists(annotation_output_directory):\n",
    "        os.makedirs(annotation_output_directory)\n",
    "\n",
    "    # Get the dimensions of the full image\n",
    "    full_image = Image.open(full_image_path_tif)\n",
    "    full_image_width, full_image_height = full_image.size\n",
    "    full_image_width_factor, full_image_height_factor = (\n",
    "        full_image_width / 100.0,\n",
    "        full_image_height / 100.0,\n",
    "    )\n",
    "\n",
    "    # Calculate the number of rows and columns needed\n",
    "    num_cols = int(np.ceil((full_image_width - OVERLAP) / (TILE_SIZE - OVERLAP)))\n",
    "    num_rows = int(np.ceil((full_image_height - OVERLAP) / (TILE_SIZE - OVERLAP)))\n",
    "\n",
    "    # Get the limits of all the cropped images\n",
    "    cropping_limits_x = np.array(\n",
    "        [\n",
    "            [i * (TILE_SIZE - OVERLAP), (i + 1) * (TILE_SIZE - OVERLAP) + OVERLAP]\n",
    "            for i in range(num_cols)\n",
    "        ]\n",
    "    )\n",
    "    cropping_limits_y = np.array(\n",
    "        [\n",
    "            [j * (TILE_SIZE - OVERLAP), (j + 1) * (TILE_SIZE - OVERLAP) + OVERLAP]\n",
    "            for j in range(num_rows)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bboxes_repartition = [[[] for _ in range(num_rows)] for _ in range(num_cols)]\n",
    "    for index, bbox_info in enumerate(bboxes_json[\"result\"]):\n",
    "        bbox = bbox_info[\"value\"]\n",
    "        min_x = int(np.round(bbox[\"x\"] * full_image_width_factor))\n",
    "        min_y = int(np.round(bbox[\"y\"] * full_image_height_factor))\n",
    "        max_x = int(np.round((bbox[\"x\"] + bbox[\"width\"]) * full_image_width_factor))\n",
    "        max_y = int(np.round((bbox[\"y\"] + bbox[\"height\"]) * full_image_height_factor))\n",
    "        # Find the indices of the cropped images in which the bounding box fits\n",
    "        i_x_0 = min_x // (TILE_SIZE - OVERLAP)\n",
    "        i_y_0 = min_y // (TILE_SIZE - OVERLAP)\n",
    "\n",
    "        found_image = False  # To check if the bounding box fits entirely in at least one cropped image\n",
    "\n",
    "        # Check the 4 possibilities\n",
    "        if max_x < (i_x_0 + 1) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "            # First possible image (bottom right)\n",
    "            if max_y < (i_y_0 + 1) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "                bboxes_repartition[i_x_0][i_y_0].append(index)\n",
    "                found_image = True\n",
    "            # Second possible image (top right)\n",
    "            if max_y < (i_y_0) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "                bboxes_repartition[i_x_0][i_y_0 - 1].append(index)\n",
    "                found_image = True\n",
    "        if max_x < (i_x_0) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "            # Third possible image (bottom left)\n",
    "            if max_y < (i_y_0 + 1) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "                bboxes_repartition[i_x_0 - 1][i_y_0].append(index)\n",
    "                found_image = True\n",
    "            # Fourth possible image (top left)\n",
    "            if max_y < (i_y_0) * (TILE_SIZE - OVERLAP) + OVERLAP:\n",
    "                bboxes_repartition[i_x_0 - 1][i_y_0 - 1].append(index)\n",
    "                found_image = True\n",
    "\n",
    "        if not found_image:\n",
    "            raise Exception(\n",
    "                f\"The bounding box at index {index} doesn't fit entirely in any image.\"\n",
    "            )\n",
    "\n",
    "    # Create and store the cropped annotation files\n",
    "    for row in tqdm(range(num_rows)):\n",
    "        for col in tqdm(range(num_cols), leave=False):\n",
    "            bboxes_dict = {\n",
    "                \"full_image\": {\n",
    "                    \"path\": full_image_path_tif,\n",
    "                    \"coordinates_of_cropped_image\": {\n",
    "                        \"x\": col * (TILE_SIZE - OVERLAP),\n",
    "                        \"y\": row * (TILE_SIZE - OVERLAP),\n",
    "                        \"width\": TILE_SIZE,\n",
    "                        \"height\": TILE_SIZE,\n",
    "                    },\n",
    "                    \"overlap\": OVERLAP,\n",
    "                },\n",
    "                \"col\": col,\n",
    "                \"row\": row,\n",
    "                \"width\": TILE_SIZE,\n",
    "                \"height\": TILE_SIZE,\n",
    "                \"bounding_boxes\": [\n",
    "                    {\n",
    "                        \"id\": bboxes_json[\"result\"][i][\"id\"],\n",
    "                        \"index\": i,\n",
    "                        \"x\": bboxes_json[\"result\"][i][\"value\"][\"x\"]\n",
    "                        * full_image_width_factor\n",
    "                        - col * (TILE_SIZE - OVERLAP),\n",
    "                        \"y\": bboxes_json[\"result\"][i][\"value\"][\"y\"]\n",
    "                        * full_image_width_factor\n",
    "                        - row * (TILE_SIZE - OVERLAP),\n",
    "                        \"width\": bboxes_json[\"result\"][i][\"value\"][\"width\"]\n",
    "                        * full_image_width_factor,\n",
    "                        \"height\": bboxes_json[\"result\"][i][\"value\"][\"height\"]\n",
    "                        * full_image_width_factor,\n",
    "                        \"label\": bboxes_json[\"result\"][i][\"value\"][\"rectanglelabels\"][\n",
    "                            0\n",
    "                        ],\n",
    "                    }\n",
    "                    for i in bboxes_repartition[col][row]\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            annotation_output_file_name = f\"{output_image_prefix}_{row}_{col}.json\"\n",
    "            output_path = os.path.join(\n",
    "                annotation_output_directory, annotation_output_file_name\n",
    "            )\n",
    "            with open(output_path, \"w\") as outfile:\n",
    "                json.dump(bboxes_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce1247fee914393bcedf7915c0c3590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/9 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All this can also be done using gdal_retile.py\n",
    "\n",
    "# Define output paths\n",
    "image_output_directory = os.path.join(CROPPED_IMAGES_FOLDER, output_image_prefix)\n",
    "if not os.path.exists(image_output_directory):\n",
    "    os.makedirs(image_output_directory)\n",
    "\n",
    "# Iterate over rows and columns to create tiles\n",
    "for row in tqdm(range(num_rows)):\n",
    "    for col in tqdm(range(num_cols), leave=False):\n",
    "        # Calculate the pixel offsets for the tile\n",
    "        x_offset = col * (TILE_SIZE - OVERLAP)\n",
    "        y_offset = row * (TILE_SIZE - OVERLAP)\n",
    "\n",
    "        # Create output file_name\n",
    "        output_file_name = f\"{output_image_prefix}_{row}_{col}.tif\"\n",
    "        output_path = os.path.join(image_output_directory, output_file_name)\n",
    "\n",
    "        # Define the subset area to read from the input image\n",
    "        window = (x_offset, y_offset, TILE_SIZE, TILE_SIZE)\n",
    "\n",
    "        gdal.Translate(output_path, full_image_path_tif, srcWin=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution of crop_las(('../../data/point_clouds_geotiles/25GN1_13.LAZ', '../../data/point_clouds_geotiles_no_overlap/25GN1_13.LAZ', (122000.0, 122999.999), (483750.0, 484999.999)))...\n",
      "Done in 47.111 seconds\n",
      "Execution of crop_las(('../../data/point_clouds_geotiles/25GN1_18.LAZ', '../../data/point_clouds_geotiles_no_overlap/25GN1_18.LAZ', (122000.0, 122999.999), (482500.0, 483749.999)))...\n",
      "Done in 49.171 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71789a70ea4a429c91a848ddc6df4b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/9 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_0.laz', (122000.0, 122153.6), (483846.4, 484000.0)))...\n",
      "Done in 10.468 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_0_filtered.laz'))...\n",
      "Done in 0.479 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_1.laz', (122115.2, 122268.8), (483846.4, 484000.0)))...\n",
      "Done in 10.387 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_1_filtered.laz'))...\n",
      "Done in 0.478 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_2.laz', (122230.4, 122384.0), (483846.4, 484000.0)))...\n",
      "Done in 10.357 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_2_filtered.laz'))...\n",
      "Done in 0.447 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_3.laz', (122345.6, 122499.2), (483846.4, 484000.0)))...\n",
      "Done in 10.527 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_3_filtered.laz'))...\n",
      "Done in 0.369 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_4.laz', (122460.8, 122614.4), (483846.4, 484000.0)))...\n",
      "Done in 10.316 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_4_filtered.laz'))...\n",
      "Done in 0.429 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_5.laz', (122576.0, 122729.6), (483846.4, 484000.0)))...\n",
      "Done in 10.326 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_5_filtered.laz'))...\n",
      "Done in 0.508 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_6.laz', (122691.2, 122844.8), (483846.4, 484000.0)))...\n",
      "Done in 10.316 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_6_filtered.laz'))...\n",
      "Done in 0.293 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_7.laz', (122806.4, 122960.0), (483846.4, 484000.0)))...\n",
      "Done in 10.254 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_7_filtered.laz'))...\n",
      "Done in 0.111 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 484000.0, 483846.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_8.laz', (122921.6, 123075.2), (483846.4, 484000.0)))...\n",
      "Done in 10.277 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_0_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_0_8_filtered.laz'))...\n",
      "Done in 0.128 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_0.laz', (122000.0, 122153.6), (483731.2, 483884.8)))...\n",
      "Done in 10.372 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_0_filtered.laz'))...\n",
      "Done in 0.442 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_1.laz', (122115.2, 122268.8), (483731.2, 483884.8)))...\n",
      "Done in 10.235 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_1_filtered.laz'))...\n",
      "Done in 0.552 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_2.laz', (122230.4, 122384.0), (483731.2, 483884.8)))...\n",
      "Done in 10.555 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_2_filtered.laz'))...\n",
      "Done in 0.592 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_3.laz', (122345.6, 122499.2), (483731.2, 483884.8)))...\n",
      "Done in 10.462 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_3_filtered.laz'))...\n",
      "Done in 0.563 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_4.laz', (122460.8, 122614.4), (483731.2, 483884.8)))...\n",
      "Done in 10.165 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_4_filtered.laz'))...\n",
      "Done in 0.688 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_5.laz', (122576.0, 122729.6), (483731.2, 483884.8)))...\n",
      "Done in 10.579 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_5_filtered.laz'))...\n",
      "Done in 0.596 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_6.laz', (122691.2, 122844.8), (483731.2, 483884.8)))...\n",
      "Done in 10.097 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_6_filtered.laz'))...\n",
      "Done in 0.162 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_7.laz', (122806.4, 122960.0), (483731.2, 483884.8)))...\n",
      "Done in 9.978 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_7_filtered.laz'))...\n",
      "Done in 0.046 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483884.8, 483731.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_8.laz', (122921.6, 123075.2), (483731.2, 483884.8)))...\n",
      "Done in 10.136 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_1_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_1_8_filtered.laz'))...\n",
      "Done in 0.115 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_0.laz', (122000.0, 122153.6), (483616.0, 483769.6)))...\n",
      "Done in 10.561 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_0_filtered.laz'))...\n",
      "Done in 0.706 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_1.laz', (122115.2, 122268.8), (483616.0, 483769.6)))...\n",
      "Done in 10.543 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_1_filtered.laz'))...\n",
      "Done in 0.742 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_2.laz', (122230.4, 122384.0), (483616.0, 483769.6)))...\n",
      "Done in 10.479 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_2_filtered.laz'))...\n",
      "Done in 0.803 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_3.laz', (122345.6, 122499.2), (483616.0, 483769.6)))...\n",
      "Done in 10.603 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_3_filtered.laz'))...\n",
      "Done in 0.785 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_4.laz', (122460.8, 122614.4), (483616.0, 483769.6)))...\n",
      "Done in 10.407 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_4_filtered.laz'))...\n",
      "Done in 0.648 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_5.laz', (122576.0, 122729.6), (483616.0, 483769.6)))...\n",
      "Done in 10.438 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_5_filtered.laz'))...\n",
      "Done in 0.287 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_6.laz', (122691.2, 122844.8), (483616.0, 483769.6)))...\n",
      "Done in 9.986 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_6_filtered.laz'))...\n",
      "Done in 0.105 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_7.laz', (122806.4, 122960.0), (483616.0, 483769.6)))...\n",
      "Done in 10.18 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_7_filtered.laz'))...\n",
      "Done in 0.265 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_2_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483769.6, 483616.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_8.laz', (122921.6, 123075.2), (483616.0, 483769.6)))...\n",
      "Done in 10.096 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_2_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_2_8_filtered.laz'))...\n",
      "Done in 0.194 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_0.laz', (122000.0, 122153.6), (483500.8, 483654.4)))...\n",
      "Done in 10.419 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_0_filtered.laz'))...\n",
      "Done in 0.632 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_1.laz', (122115.2, 122268.8), (483500.8, 483654.4)))...\n",
      "Done in 10.426 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_1_filtered.laz'))...\n",
      "Done in 0.768 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_2.laz', (122230.4, 122384.0), (483500.8, 483654.4)))...\n",
      "Done in 10.32 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_2_filtered.laz'))...\n",
      "Done in 0.607 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_3.laz', (122345.6, 122499.2), (483500.8, 483654.4)))...\n",
      "Done in 10.098 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_3_filtered.laz'))...\n",
      "Done in 0.287 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_4.laz', (122460.8, 122614.4), (483500.8, 483654.4)))...\n",
      "Done in 10.056 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_4_filtered.laz'))...\n",
      "Done in 0.159 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_5.laz', (122576.0, 122729.6), (483500.8, 483654.4)))...\n",
      "Done in 10.098 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_5_filtered.laz'))...\n",
      "Done in 0.196 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_6.laz', (122691.2, 122844.8), (483500.8, 483654.4)))...\n",
      "Done in 10.339 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_6_filtered.laz'))...\n",
      "Done in 0.365 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_7.laz', (122806.4, 122960.0), (483500.8, 483654.4)))...\n",
      "Done in 10.246 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_7_filtered.laz'))...\n",
      "Done in 0.472 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_3_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483654.4, 483500.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_8.laz', (122921.6, 123075.2), (483500.8, 483654.4)))...\n",
      "Done in 10.226 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_3_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_3_8_filtered.laz'))...\n",
      "Done in 0.185 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_0.laz', (122000.0, 122153.6), (483385.6, 483539.2)))...\n",
      "Done in 10.716 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_0_filtered.laz'))...\n",
      "Done in 1.038 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_1.laz', (122115.2, 122268.8), (483385.6, 483539.2)))...\n",
      "Done in 10.746 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_1_filtered.laz'))...\n",
      "Done in 1.01 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_2.laz', (122230.4, 122384.0), (483385.6, 483539.2)))...\n",
      "Done in 10.18 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_2_filtered.laz'))...\n",
      "Done in 0.279 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_3.laz', (122345.6, 122499.2), (483385.6, 483539.2)))...\n",
      "Done in 10.692 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_3_filtered.laz'))...\n",
      "Done in 0.572 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_4.laz', (122460.8, 122614.4), (483385.6, 483539.2)))...\n",
      "Done in 10.947 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_4_filtered.laz'))...\n",
      "Done in 1.132 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_5.laz', (122576.0, 122729.6), (483385.6, 483539.2)))...\n",
      "Done in 10.459 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_5_filtered.laz'))...\n",
      "Done in 0.656 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_6.laz', (122691.2, 122844.8), (483385.6, 483539.2)))...\n",
      "Done in 10.453 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_6_filtered.laz'))...\n",
      "Done in 0.589 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_7.laz', (122806.4, 122960.0), (483385.6, 483539.2)))...\n",
      "Done in 10.522 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_7_filtered.laz'))...\n",
      "Done in 0.742 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_4_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483539.2, 483385.6)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_8.laz', (122921.6, 123075.2), (483385.6, 483539.2)))...\n",
      "Done in 10.482 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_4_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_4_8_filtered.laz'))...\n",
      "Done in 0.385 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_0.laz', (122000.0, 122153.6), (483270.4, 483424.0)))...\n",
      "Done in 10.919 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_0_filtered.laz'))...\n",
      "Done in 1.113 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_1.laz', (122115.2, 122268.8), (483270.4, 483424.0)))...\n",
      "Done in 10.442 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_1_filtered.laz'))...\n",
      "Done in 0.977 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_2.laz', (122230.4, 122384.0), (483270.4, 483424.0)))...\n",
      "Done in 10.182 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_2_filtered.laz'))...\n",
      "Done in 0.268 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_3.laz', (122345.6, 122499.2), (483270.4, 483424.0)))...\n",
      "Done in 11.332 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_3_filtered.laz'))...\n",
      "Done in 1.539 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_4.laz', (122460.8, 122614.4), (483270.4, 483424.0)))...\n",
      "Done in 11.761 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_4_filtered.laz'))...\n",
      "Done in 1.65 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_5.laz', (122576.0, 122729.6), (483270.4, 483424.0)))...\n",
      "Done in 11.197 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_5_filtered.laz'))...\n",
      "Done in 0.928 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_6.laz', (122691.2, 122844.8), (483270.4, 483424.0)))...\n",
      "Done in 10.852 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_6_filtered.laz'))...\n",
      "Done in 0.549 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_7.laz', (122806.4, 122960.0), (483270.4, 483424.0)))...\n",
      "Done in 10.777 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_7_filtered.laz'))...\n",
      "Done in 0.895 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_5_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483424.0, 483270.4)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_8.laz', (122921.6, 123075.2), (483270.4, 483424.0)))...\n",
      "Done in 10.322 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_5_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_5_8_filtered.laz'))...\n",
      "Done in 0.48 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_0.laz', (122000.0, 122153.6), (483155.2, 483308.8)))...\n",
      "Done in 11.074 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_0_filtered.laz'))...\n",
      "Done in 1.544 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_1.laz', (122115.2, 122268.8), (483155.2, 483308.8)))...\n",
      "Done in 10.404 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_1_filtered.laz'))...\n",
      "Done in 0.708 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_2.laz', (122230.4, 122384.0), (483155.2, 483308.8)))...\n",
      "Done in 10.368 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_2_filtered.laz'))...\n",
      "Done in 0.289 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_3.laz', (122345.6, 122499.2), (483155.2, 483308.8)))...\n",
      "Done in 10.667 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_3_filtered.laz'))...\n",
      "Done in 1.181 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_4.laz', (122460.8, 122614.4), (483155.2, 483308.8)))...\n",
      "Done in 10.946 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_4_filtered.laz'))...\n",
      "Done in 1.348 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_5.laz', (122576.0, 122729.6), (483155.2, 483308.8)))...\n",
      "Done in 10.737 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_5_filtered.laz'))...\n",
      "Done in 0.824 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_6.laz', (122691.2, 122844.8), (483155.2, 483308.8)))...\n",
      "Done in 10.213 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_6_filtered.laz'))...\n",
      "Done in 0.436 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_7.laz', (122806.4, 122960.0), (483155.2, 483308.8)))...\n",
      "Done in 11.066 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_7_filtered.laz'))...\n",
      "Done in 0.736 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_6_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483308.8, 483155.2)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_8.laz', (122921.6, 123075.2), (483155.2, 483308.8)))...\n",
      "Done in 10.669 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_6_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_6_8_filtered.laz'))...\n",
      "Done in 0.281 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_0.laz', (122000.0, 122153.6), (483040.0, 483193.6)))...\n",
      "Done in 10.843 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_0_filtered.laz'))...\n",
      "Done in 1.194 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_1.laz', (122115.2, 122268.8), (483040.0, 483193.6)))...\n",
      "Done in 10.115 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_1_filtered.laz'))...\n",
      "Done in 0.344 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_2.laz', (122230.4, 122384.0), (483040.0, 483193.6)))...\n",
      "Done in 10.421 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_2_filtered.laz'))...\n",
      "Done in 0.704 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_3.laz', (122345.6, 122499.2), (483040.0, 483193.6)))...\n",
      "Done in 10.426 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_3_filtered.laz'))...\n",
      "Done in 0.748 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_4.laz', (122460.8, 122614.4), (483040.0, 483193.6)))...\n",
      "Done in 10.523 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_4_filtered.laz'))...\n",
      "Done in 0.813 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_5.laz', (122576.0, 122729.6), (483040.0, 483193.6)))...\n",
      "Done in 10.37 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_5_filtered.laz'))...\n",
      "Done in 0.595 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_6.laz', (122691.2, 122844.8), (483040.0, 483193.6)))...\n",
      "Done in 10.423 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_6_filtered.laz'))...\n",
      "Done in 0.281 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_7.laz', (122806.4, 122960.0), (483040.0, 483193.6)))...\n",
      "Done in 10.326 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_7_filtered.laz'))...\n",
      "Done in 0.286 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_7_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483193.6, 483040.0)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_8.laz', (122921.6, 123075.2), (483040.0, 483193.6)))...\n",
      "Done in 10.191 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_7_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_7_8_filtered.laz'))...\n",
      "Done in 0.127 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_0.tif'\n",
      "(x1, x2, y1, y2) = (122000.0, 122153.6, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_0.laz', (122000.0, 122153.6), (482924.8, 483078.4)))...\n",
      "Done in 10.266 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_0.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_0_filtered.laz'))...\n",
      "Done in 0.273 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_1.tif'\n",
      "(x1, x2, y1, y2) = (122115.2, 122268.8, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_1.laz', (122115.2, 122268.8), (482924.8, 483078.4)))...\n",
      "Done in 10.004 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_1.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_1_filtered.laz'))...\n",
      "Done in 0.11 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_2.tif'\n",
      "(x1, x2, y1, y2) = (122230.4, 122384.0, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_2.laz', (122230.4, 122384.0), (482924.8, 483078.4)))...\n",
      "Done in 10.399 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_2.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_2_filtered.laz'))...\n",
      "Done in 0.473 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_3.tif'\n",
      "(x1, x2, y1, y2) = (122345.6, 122499.2, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_3.laz', (122345.6, 122499.2), (482924.8, 483078.4)))...\n",
      "Done in 10.279 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_3.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_3_filtered.laz'))...\n",
      "Done in 0.392 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_4.tif'\n",
      "(x1, x2, y1, y2) = (122460.8, 122614.4, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_4.laz', (122460.8, 122614.4), (482924.8, 483078.4)))...\n",
      "Done in 10.286 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_4.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_4_filtered.laz'))...\n",
      "Done in 0.415 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_5.tif'\n",
      "(x1, x2, y1, y2) = (122576.0, 122729.6, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_5.laz', (122576.0, 122729.6), (482924.8, 483078.4)))...\n",
      "Done in 10.112 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_5.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_5_filtered.laz'))...\n",
      "Done in 0.349 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_6.tif'\n",
      "(x1, x2, y1, y2) = (122691.2, 122844.8, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_6.laz', (122691.2, 122844.8), (482924.8, 483078.4)))...\n",
      "Done in 9.993 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_6.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_6_filtered.laz'))...\n",
      "Done in 0.138 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_7.tif'\n",
      "(x1, x2, y1, y2) = (122806.4, 122960.0, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_7.laz', (122806.4, 122960.0), (482924.8, 483078.4)))...\n",
      "Done in 10.004 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_7.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_7_filtered.laz'))...\n",
      "Done in 0.139 seconds\n",
      "corresponding_image_path = '../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_8_8.tif'\n",
      "(x1, x2, y1, y2) = (122921.6, 123075.2, 483078.4, 482924.8)\n",
      "Execution of crop_las(('../../data/point_clouds_full/122000_484000_filtered.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_8.laz', (122921.6, 123075.2), (482924.8, 483078.4)))...\n",
      "Done in 10.07 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_cropped/122000_484000/122000_484000_8_8.laz', '../../data/point_clouds_cropped/122000_484000/122000_484000_8_8_filtered.laz'))...\n",
      "Done in 0.128 seconds\n"
     ]
    }
   ],
   "source": [
    "remove_las_overlap_from_geotiles_all()\n",
    "\n",
    "\n",
    "def get_coordinates_from_image_file_name(file_name: str):\n",
    "    return (int(file_name[5:11]), int(file_name[12:18]))\n",
    "\n",
    "\n",
    "output_coordinates = get_coordinates_from_image_file_name(output_image_prefix)\n",
    "output_coordinates_prefix = f\"{output_coordinates[0]}_{output_coordinates[1]}\"\n",
    "\n",
    "# Define output paths\n",
    "point_cloud_output_directory = os.path.join(\n",
    "    CROPPED_LIDAR_FOLDER, output_coordinates_prefix\n",
    ")\n",
    "if not os.path.exists(point_cloud_output_directory):\n",
    "    os.makedirs(point_cloud_output_directory)\n",
    "\n",
    "full_point_cloud_path = (\n",
    "    f\"../../data/point_clouds_full/{output_coordinates_prefix}_filtered.laz\"\n",
    ")\n",
    "\n",
    "# Iterate over rows and columns to create tiles\n",
    "for row in tqdm(range(num_rows)):\n",
    "    for col in tqdm(range(num_cols), leave=False):\n",
    "        # Create output file_name\n",
    "        output_point_cloud_file_name = f\"{output_coordinates_prefix}_{row}_{col}.laz\"\n",
    "        output_point_cloud_path = os.path.join(\n",
    "            point_cloud_output_directory, output_point_cloud_file_name\n",
    "        )\n",
    "        output_point_cloud_filtered_file_name = (\n",
    "            f\"{output_coordinates_prefix}_{row}_{col}_filtered.laz\"\n",
    "        )\n",
    "        output_point_cloud_filtered_path = os.path.join(\n",
    "            point_cloud_output_directory, output_point_cloud_filtered_file_name\n",
    "        )\n",
    "\n",
    "        if os.path.exists(output_point_cloud_path) and os.path.exists(\n",
    "            output_point_cloud_filtered_path\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Get the corresponding image\n",
    "        corresponding_image_file_name = f\"{output_image_prefix}_{row}_{col}.tif\"\n",
    "        corresponding_image_path = os.path.join(\n",
    "            image_output_directory, corresponding_image_file_name\n",
    "        )\n",
    "        print(f\"{corresponding_image_path = }\")\n",
    "\n",
    "        ### Get the coordinates\n",
    "        ds = gdal.Open(corresponding_image_path)\n",
    "        # Get the geotransform parameters\n",
    "        gt = ds.GetGeoTransform()\n",
    "        # Calculate the image coordinates\n",
    "        width = ds.RasterXSize\n",
    "        height = ds.RasterYSize\n",
    "        # Calculate the coordinates of the four corners\n",
    "        x1 = round(gt[0], 3)\n",
    "        y1 = round(gt[3], 3)\n",
    "        x2 = round(gt[0] + (gt[1] * width), 3)\n",
    "        y2 = round(gt[3] + (gt[5] * height), 3)\n",
    "        # Close the dataset\n",
    "        ds = None\n",
    "\n",
    "        print(f\"{(x1, x2, y1, y2) = }\")\n",
    "\n",
    "        crop_las(full_point_cloud_path, output_point_cloud_path, (x1, x2), (y2, y1))\n",
    "        filter_classification_las(\n",
    "            output_point_cloud_path, output_point_cloud_filtered_path\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_boxes(image_path: str, boxes: list | None = None) -> None:\n",
    "    reduction_ratio = 3\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path)\n",
    "    image_smaller = Image.open(image_path)\n",
    "    image_smaller.thumbnail(\n",
    "        (TILE_SIZE // reduction_ratio, TILE_SIZE // reduction_ratio)\n",
    "    )\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(20, 40))\n",
    "\n",
    "    # Display image\n",
    "    axs[0].imshow(image)\n",
    "    axs[1].imshow(image_smaller)\n",
    "\n",
    "    # Annotation colors\n",
    "    colors = {\n",
    "        \"Tree\": \"#9effb1\",\n",
    "        \"Tree_unsure\": \"#ffd79e\",\n",
    "        \"Tree_disappeared\": \"#9eaeff\",\n",
    "        \"Tree_replaced\": \"#ff5a52\",\n",
    "        \"Tree_new\": \"#fb6ae1\",\n",
    "    }\n",
    "\n",
    "    # Add bounding boxes if provided\n",
    "    if boxes:\n",
    "        for box in boxes:\n",
    "            # Extract box coordinates\n",
    "            x, y, width, height, label = box\n",
    "            # Create a Rectangle patch\n",
    "            rect = Rectangle(\n",
    "                (x, y),\n",
    "                width,\n",
    "                height,\n",
    "                linewidth=1,\n",
    "                edgecolor=colors[label],\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            # Add the patch to the Axes\n",
    "            axs[0].add_patch(rect)\n",
    "            # Create a Rectangle patch\n",
    "            rect = Rectangle(\n",
    "                (x // reduction_ratio, y // reduction_ratio),\n",
    "                width // reduction_ratio,\n",
    "                height // reduction_ratio,\n",
    "                linewidth=1,\n",
    "                edgecolor=colors[label],\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "            # Add the patch to the Axes\n",
    "            axs[1].add_patch(rect)\n",
    "\n",
    "    # Add each rectangle to the legend individually\n",
    "    for label, color in colors.items():\n",
    "        axs[0].add_patch(Rectangle((0, 0), 0, 0, color=color, label=label))\n",
    "        axs[1].add_patch(Rectangle((0, 0), 0, 0, color=color, label=label))\n",
    "\n",
    "    axs[0].set_axis_off()\n",
    "    axs[0].legend()\n",
    "    axs[1].set_axis_off()\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_bounding_boxes(bboxes_path: str) -> list:\n",
    "    with open(bboxes_path, \"r\") as file:\n",
    "        # Load the annotation data\n",
    "        bboxes_json = json.load(file)\n",
    "\n",
    "        # Get every bounding box\n",
    "        bboxes = []\n",
    "        for bbox in bboxes_json[\"bounding_boxes\"]:\n",
    "            bboxes.append(\n",
    "                (bbox[\"x\"], bbox[\"y\"], bbox[\"width\"], bbox[\"height\"], bbox[\"label\"])\n",
    "            )\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "image_path = \"../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_3.tif\"\n",
    "bboxes_path = \"../../data/annotations_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_1_3.json\"\n",
    "\n",
    "# bboxes = get_bounding_boxes(bboxes_path)\n",
    "# display_image_with_boxes(image_path, bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate points removal (post-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_points(input_las_file, output_las_file):\n",
    "    # Open the input LAS file\n",
    "    in_las = laspy.read(input_las_file)\n",
    "    # Convert coordinates and all dimensions to a NumPy array\n",
    "    points = np.column_stack(\n",
    "        [getattr(in_las, dim) for dim in in_las.point_format.dimension_names]\n",
    "    )\n",
    "    # Find unique points\n",
    "    unique_points, idx = np.unique(points, axis=0, return_index=True)\n",
    "    # Extract unique coordinates\n",
    "    num_points = len(unique_points)\n",
    "    # Create a new LAS file\n",
    "    out_header = in_las.header\n",
    "    out_header.point_count = num_points\n",
    "    out_las = laspy.LasData(out_header)\n",
    "    # Set all dimensions in the output LAS file\n",
    "    for dim_idx, dim_name in enumerate(in_las.point_format.dimension_names):\n",
    "        dim_values = unique_points[:, dim_idx]\n",
    "        # If the dimension is not used, don't set it\n",
    "        if np.all(dim_values == dim_values[0]):\n",
    "            print(dim_name)\n",
    "            continue\n",
    "        setattr(out_las, dim_name, dim_values)\n",
    "    out_las.write(output_las_file)\n",
    "\n",
    "\n",
    "def las_to_laz(input_las_path: str):\n",
    "    input_las_path_no_extension, initial_extension = os.path.splitext(input_las_path)\n",
    "    if initial_extension not in [\".las\", \".LAS\"]:\n",
    "        raise Exception(\"The input must be a LAS file.\")\n",
    "    output_laz_path = input_las_path_no_extension + \".laz\"\n",
    "    pipeline_list = [\n",
    "        {\n",
    "            \"type\": \"readers.las\",\n",
    "            \"file_name\": input_las_path,\n",
    "        },\n",
    "        {\"type\": \"writers.las\", \"file_name\": output_laz_path},\n",
    "    ]\n",
    "    pprint(json.dumps(pipeline_list))\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "    pipeline.execute()\n",
    "\n",
    "\n",
    "# # Usage\n",
    "# input_las_file = \"../../data/point_clouds_full/122000_484000_with_duplicates_2.las\"\n",
    "# output_las_file = \"../../data/point_clouds_full/122000_484000_2.laz\"\n",
    "# output_las_file_2 = \"../../data/point_clouds_full/122000_484000_3_2.las\"\n",
    "# las_to_laz(input_las_file)\n",
    "# remove_duplicate_points(input_las_file, output_las_file)\n",
    "# remove_duplicate_points(input_las_file, output_las_file_2)\n",
    "# las_to_laz(output_las_file_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates verifications for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum X: 122000.0\n",
      "Maximum X: 122153.6\n",
      "Minimum Y: 484000.0\n",
      "Maximum Y: 483846.4\n",
      "width = 1920\n",
      "height = 1920\n",
      "Minimum X: 122000.0\n",
      "Maximum X: 122153.6\n",
      "Minimum Y: 483846.4\n",
      "Maximum Y: 484000.0\n",
      "Width: 153.60000000000582\n",
      "Height: 153.59999999997672\n",
      "12.5\n",
      "153.6\n",
      "38.4\n",
      "115.2\n"
     ]
    }
   ],
   "source": [
    "### Get the coordinates\n",
    "ds = gdal.Open(\n",
    "    \"../../data/images_cropped/2023_122000_484000_RGB_hrl/2023_122000_484000_RGB_hrl_0_0.tif\"\n",
    ")\n",
    "# Get the geotransform parameters\n",
    "gt = ds.GetGeoTransform()\n",
    "# Calculate the image coordinates\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "# Calculate the coordinates of the four corners\n",
    "x1 = round(gt[0], 3)\n",
    "y1 = round(gt[3], 3)\n",
    "x2 = round(gt[0] + (gt[1] * width), 3)\n",
    "y2 = round(gt[3] + (gt[5] * height), 3)\n",
    "# Close the dataset\n",
    "ds = None\n",
    "\n",
    "print(\"Minimum X:\", x1)\n",
    "print(\"Maximum X:\", x2)\n",
    "print(\"Minimum Y:\", y1)\n",
    "print(\"Maximum Y:\", y2)\n",
    "print(f\"{width = }\")\n",
    "print(f\"{height = }\")\n",
    "\n",
    "with laspy.open(\n",
    "    \"../../data/point_clouds_cropped/122000_484000/122000_484000_0_0_filtered.laz\",\n",
    "    mode=\"r\",\n",
    ") as las_file:\n",
    "    # Get the bounding box information from the header\n",
    "    min_x = las_file.header.min[0]\n",
    "    max_x = las_file.header.max[0]\n",
    "    min_y = las_file.header.min[1]\n",
    "    max_y = las_file.header.max[1]\n",
    "    min_z = las_file.header.min[2]\n",
    "    max_z = las_file.header.max[2]\n",
    "\n",
    "# Print out the bounds\n",
    "print(\"Minimum X:\", min_x)\n",
    "print(\"Maximum X:\", max_x)\n",
    "print(\"Minimum Y:\", min_y)\n",
    "print(\"Maximum Y:\", max_y)\n",
    "print(\"Width:\", max_x - min_x)\n",
    "print(\"Height:\", max_y - min_y)\n",
    "\n",
    "# with laspy.open(f\"../../data/point_clouds_test/122000_484000_filtered_1.laz\", mode=\"r\") as las_file:\n",
    "#     # Get the bounding box information from the header\n",
    "#     min_x = las_file.header.min[0]\n",
    "#     max_x = las_file.header.max[0]\n",
    "#     min_y = las_file.header.min[1]\n",
    "#     max_y = las_file.header.max[1]\n",
    "#     min_z = las_file.header.min[2]\n",
    "#     max_z = las_file.header.max[2]\n",
    "\n",
    "# # Print out the bounds\n",
    "# print(\"Minimum X:\", min_x)\n",
    "# print(\"Maximum X:\", max_x)\n",
    "# print(\"Minimum Y:\", min_y)\n",
    "# print(\"Maximum Y:\", max_y)\n",
    "# print(\"Width:\", max_x - min_x)\n",
    "# print(\"Height:\", max_y - min_y)\n",
    "\n",
    "print(1920 / 153.6)\n",
    "print(1920 * 153.6 / 1920)\n",
    "print(480 * 153.6 / 1920)\n",
    "print((1920 - 480) * 153.6 / 1920)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop point clouds in one PDAL pipeline (not working yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_point_cloud(input_file, output_folder):\n",
    "    # Construct the PDAL pipeline\n",
    "    pipeline_list = [\n",
    "        {\n",
    "            \"type\": \"readers.las\",\n",
    "            \"file_name\": input_file,\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"filters.splitter\",\n",
    "            \"length\": \"50\",\n",
    "            \"buffer\": \"20\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"writers.las\",\n",
    "            \"file_name\": os.path.join(\n",
    "                output_folder,\n",
    "                f\"{os.path.basename(os.path.splitext(input_file)[0])}_#.laz\",\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the pipeline\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_list))\n",
    "    pipeline.execute()\n",
    "\n",
    "\n",
    "# Specify the input LAS/LAZ file\n",
    "input_file = \"../../data/point_clouds_full/122000_484000_filtered.laz\"\n",
    "\n",
    "# Specify the output folder\n",
    "point_cloud_test_output_folder = \"../../data/point_clouds_test\"\n",
    "if not os.path.exists(point_cloud_test_output_folder):\n",
    "    os.makedirs(point_cloud_test_output_folder)\n",
    "\n",
    "# Crop the point cloud into tiles\n",
    "crop_point_cloud(input_file, point_cloud_test_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the point clouds corresponding to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://geotiles.citg.tudelft.nl/AHN4_T/25GN1_13.LAZ... Saved as '../../data/point_clouds_geotiles/25GN1_13.LAZ'\n",
      "Execution of crop_las(('../../data/point_clouds_geotiles/25GN1_13.LAZ', '../../data/point_clouds_geotiles_no_overlap/25GN1_13.LAZ', (122000.0, 122999.999), (483750.0, 484999.999)))...\n",
      "Done in 47.519 seconds\n",
      "Downloading https://geotiles.citg.tudelft.nl/AHN4_T/25GN1_18.LAZ... Saved as '../../data/point_clouds_geotiles/25GN1_18.LAZ'\n",
      "Execution of crop_las(('../../data/point_clouds_geotiles/25GN1_18.LAZ', '../../data/point_clouds_geotiles_no_overlap/25GN1_18.LAZ', (122000.0, 122999.999), (482500.0, 483749.999)))...\n",
      "Done in 47.76 seconds\n",
      "Execution of merge_crop_las((['../../data/point_clouds_geotiles_no_overlap/25GN1_13.LAZ', '../../data/point_clouds_geotiles_no_overlap/25GN1_18.LAZ'], '../../data/point_clouds_full/122000_484000.laz', (122000.0, 123000.0), (483000.0, 484000.0)))...\n",
      "Done in 50.813 seconds\n",
      "Execution of filter_classification_las(('../../data/point_clouds_full/122000_484000.laz', '../../data/point_clouds_full/122000_484000_filtered.laz'))...\n",
      "Done in 28.508 seconds\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal, ogr\n",
    "from shapely.geometry import box\n",
    "from shapely.wkt import dumps\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Open the file in binary write mode and write the content of the response\n",
    "        print(f\"Downloading {url}...\", end=\" \", flush=True)\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved as '{save_path}'\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to download file from '{url}'. Status code: {response.status_code}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Path to your TIF image\n",
    "tif_file = full_image_path_tif\n",
    "\n",
    "# Path to your Shapefile\n",
    "shapefile = (\n",
    "    \"../../data/point_clouds_geotiles/TOP-AHN_subunit_compat/TOP-AHN_subunit_compat.shp\"\n",
    ")\n",
    "\n",
    "# Open the TIF image\n",
    "ds = gdal.Open(tif_file)\n",
    "\n",
    "# Get the geotransform and projection\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "\n",
    "# Get the extent of the TIF image\n",
    "min_x = gt[0]\n",
    "max_y = gt[3]\n",
    "max_x = min_x + gt[1] * ds.RasterXSize\n",
    "min_y = max_y + gt[5] * ds.RasterYSize\n",
    "\n",
    "# Create a box geometry representing the extent of the TIF image\n",
    "overlap = 20\n",
    "bbox = box(min_x + overlap, min_y + overlap, max_x - overlap, max_y - overlap)\n",
    "\n",
    "# Convert the Shapely geometry to an ogr.Geometry object\n",
    "bbox_ogr = ogr.CreateGeometryFromWkt(dumps(bbox))\n",
    "\n",
    "# Open the Shapefile\n",
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "shp_ds = driver.Open(shapefile, 0)\n",
    "layer = shp_ds.GetLayer()\n",
    "\n",
    "# Get the intersection between TIF image and Shapefile\n",
    "intersection_file_names = []\n",
    "for feature in layer:\n",
    "    geom = feature.GetGeometryRef()\n",
    "    if geom.Intersects(bbox_ogr):\n",
    "        intersection_file_names.append(\n",
    "            feature.GetField(\"AHN\")\n",
    "        )  # Replace \"file_name_column\" with the actual column name\n",
    "\n",
    "# Close the Shapefile\n",
    "shp_ds = None\n",
    "\n",
    "\n",
    "intersection_file_paths = []\n",
    "for file_name in intersection_file_names:\n",
    "    url = f\"https://geotiles.citg.tudelft.nl/AHN4_T/{file_name}.LAZ\"\n",
    "    # Create the paths\n",
    "    geotiles_with_overlap_path = os.path.join(GEOTILES_LIDAR_FOLDER, f\"{file_name}.LAZ\")\n",
    "    geotiles_without_overlap_path = os.path.join(\n",
    "        GEOTILES_NO_OVERLAP_LIDAR_FOLDER, f\"{file_name}.LAZ\"\n",
    "    )\n",
    "    intersection_file_paths.append(geotiles_without_overlap_path)\n",
    "    # Download the point clouds\n",
    "    if not os.path.exists(geotiles_with_overlap_path):\n",
    "        download_file(url, geotiles_with_overlap_path)\n",
    "    # Remove the overlap from the point clouds\n",
    "    if not os.path.exists(geotiles_without_overlap_path):\n",
    "        remove_las_overlap_from_geotiles(\n",
    "            geotiles_with_overlap_path, geotiles_without_overlap_path\n",
    "        )\n",
    "\n",
    "# Crop the point clouds into the area of the full image\n",
    "full_point_cloud_path = f\"../../data/point_clouds_full/{int(min_x)}_{int(max_y)}.laz\"\n",
    "if not os.path.exists(full_point_cloud_path):\n",
    "    merge_crop_las(\n",
    "        intersection_file_paths, full_point_cloud_path, (min_x, max_x), (min_y, max_y)\n",
    "    )\n",
    "\n",
    "# Filter the full point cloud to remove buildings\n",
    "full_point_filtered_cloud_path = (\n",
    "    f\"../../data/point_clouds_full/{int(min_x)}_{int(max_y)}_filtered.laz\"\n",
    ")\n",
    "if not os.path.exists(full_point_filtered_cloud_path):\n",
    "    filter_classification_las(full_point_cloud_path, full_point_filtered_cloud_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform QGIS bounding boxes to Label Studio format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_qgis_to_label_studio(\n",
    "    input_folder: str, output_json_path: str, image_path: str, task_id: int\n",
    ") -> None:\n",
    "    bboxes_dict = {\n",
    "        \"id\": task_id,\n",
    "        \"annotations\": [{\"result\": []}],\n",
    "        \"data\": {\"image\": f\"/data/local-files/?d={image_path}\"},\n",
    "    }\n",
    "\n",
    "    ds = gdal.Open(image_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    width = ds.RasterXSize\n",
    "    height = ds.RasterYSize\n",
    "    xmin = round(gt[0], 3)\n",
    "    ymax = round(gt[3], 3)\n",
    "    xmax = round(gt[0] + (gt[1] * width), 3)\n",
    "    ymin = round(gt[3] + (gt[5] * height), 3)\n",
    "    width_factor = 100 / (xmax - xmin)\n",
    "    height_factor = 100 / (ymax - ymin)\n",
    "    ds = None\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        # Check if the file is a regular file (not a directory)\n",
    "        geojson_file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.splitext(geojson_file_path)[1] == \".geojson\":\n",
    "            with open(geojson_file_path, \"r\") as file:\n",
    "                bbox_json = json.load(file)\n",
    "                coordinates = bbox_json[\"features\"][0][\"geometry\"][\"coordinates\"][0]\n",
    "                x0 = coordinates[0][0]\n",
    "                y0 = coordinates[0][1]\n",
    "                x1 = coordinates[2][0]\n",
    "                y1 = coordinates[2][1]\n",
    "                bboxes_dict[\"annotations\"][0][\"result\"].append(\n",
    "                    {\n",
    "                        \"original_width\": 12500,\n",
    "                        \"original_height\": 12500,\n",
    "                        \"value\": {\n",
    "                            \"x\": (x0 - xmin) * width_factor,\n",
    "                            \"y\": (ymax - y1 + 1) * height_factor,\n",
    "                            \"width\": (x1 - x0) * width_factor,\n",
    "                            \"height\": (y1 - y0) * height_factor,\n",
    "                            \"rotation\": 0,\n",
    "                            \"rectanglelabels\": [\"Tree\"],\n",
    "                        },\n",
    "                        \"from_name\": \"label\",\n",
    "                        \"to_name\": \"image\",\n",
    "                        \"type\": \"rectanglelabels\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    with open(output_json_path, \"w\") as outfile:\n",
    "        json.dump([bboxes_dict], outfile)\n",
    "\n",
    "\n",
    "input_folder = \"../../data/QGIS_bounding_boxes\"\n",
    "output_json = \"../../data/images_full/label_studio_pre_annotations.json\"\n",
    "image_path = \"/home/alexandre/Documents/tree-segmentation/data/images/full/2023_122000_484000_RGB_hrl.png\"\n",
    "task_id = 1\n",
    "\n",
    "bboxes_qgis_to_label_studio(input_folder, output_json, image_path, task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bboxes_label_studio_to_label_studio(\n",
    "    input_json_path: str, output_json_path: str, image_path: str, task_id: int\n",
    "):\n",
    "    bboxes_dict = {\n",
    "        # \"id\": task_id,\n",
    "        \"data\": {\"image\": f\"/data/local-files/?d={image_path}\"},\n",
    "        \"annotations\": [{\"result\": []}],\n",
    "    }\n",
    "\n",
    "    with open(input_json_path, \"r\") as file:\n",
    "        bbox_json = json.load(file)\n",
    "        bboxes_dict[\"annotations\"][0][\"result\"] = bbox_json[\"result\"]\n",
    "\n",
    "    with open(output_json_path, \"w\") as outfile:\n",
    "        json.dump(bboxes_dict, outfile)\n",
    "\n",
    "\n",
    "input_file = \"../../data/annotations/full/6\"\n",
    "output_json = \"../../data/label_studio/medium_trees.json\"\n",
    "image_path = \"home/alexandre/Documents/tree-segmentation/data/images/full/2023_122000_484000_RGB_hrl.png\"\n",
    "task_id = 1\n",
    "\n",
    "bboxes_label_studio_to_label_studio(input_file, output_json, image_path, task_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-segment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
